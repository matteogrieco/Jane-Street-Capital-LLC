{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac050af0",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-12-28T14:13:25.223931Z",
     "iopub.status.busy": "2024-12-28T14:13:25.223393Z",
     "iopub.status.idle": "2024-12-28T14:13:30.491057Z",
     "shell.execute_reply": "2024-12-28T14:13:30.489901Z"
    },
    "papermill": {
     "duration": 5.274517,
     "end_time": "2024-12-28T14:13:30.493359",
     "exception": false,
     "start_time": "2024-12-28T14:13:25.218842",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import catboost as cbt\n",
    "import numpy as np\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import kaggle_evaluation.jane_street_inference_server\n",
    "\n",
    "# !pip install lightgbm==4.2.0 -i https://mirrors.aliyun.com/pypi/simple/\n",
    "# !pip install catboost==1.2.7 -i https://mirrors.aliyun.com/pypi/simple/\n",
    "# !pip install xgboost==2.0.3 -i https://mirrors.aliyun.com/pypi/simple/\n",
    "# !pip install joblib==1.4.2 -i https://mirrors.aliyun.com/pypi/simple/\n",
    "\n",
    "def reduce_mem_usage(self, float16_as32=True):\n",
    "    # Calculate memory usage for each column, sum up to convert B -> KB -> MB\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "    \n",
    "    for col in df.columns:  # Iterate through column names\n",
    "        col_type = df[col].dtype  # Get column's data type\n",
    "        if col_type != object and str(col_type) != 'category':  # If not an object type, handle numeric variables\n",
    "            c_min, c_max = df[col].min(), df[col].max()  # Get column's min and max values\n",
    "            if str(col_type)[:3] == 'int':  # If the column type is integer, check if it's int8, int16, or int32\n",
    "                # If the range of values fits within int8, cast to int8 (-128 to 127)\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                # If the range of values fits within int16, cast to int16 (-32,768 to 32,767)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                # If the range of values fits within int32, cast to int32 (-2,147,483,648 to 2,147,483,647)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                # If the range of values fits within int64, cast to int64\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:  # If the column is a float type\n",
    "                # If the float values fit within float16 range, cast to float16 if precision allows\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    if float16_as32:  # If precision doesn't matter, use float32\n",
    "                        df[col] = df[col].astype(np.float32)\n",
    "                    else:\n",
    "                        df[col] = df[col].astype(np.float16)\n",
    "                # If the float values fit within float32 range, cast to float32\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                # If the float values fit within float64 range, cast to float64\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "\n",
    "    # Calculate memory usage after optimization\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    # Compare with the starting memory to see how much reduction occurred\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "186e744f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-28T14:13:30.500460Z",
     "iopub.status.busy": "2024-12-28T14:13:30.499852Z",
     "iopub.status.idle": "2024-12-28T14:13:30.506988Z",
     "shell.execute_reply": "2024-12-28T14:13:30.506055Z"
    },
    "papermill": {
     "duration": 0.012043,
     "end_time": "2024-12-28T14:13:30.508560",
     "exception": false,
     "start_time": "2024-12-28T14:13:30.496517",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the path to the input data directory\n",
    "# If the local directory exists, use it; otherwise, use the Kaggle input directory\n",
    "input_path = './jane-street-real-time-market-data-forecasting/' if os.path.exists('./jane-street-real-time-market-data-forecasting/') else '../jane-street-real-time-market-data-forecasting/'\n",
    "\n",
    "# Flag to determine if the script is in training mode or not\n",
    "TRAINING = False\n",
    "\n",
    "# Define the feature names based on the number of features (79 in this case)\n",
    "feature_names = [f\"feature_{i:02d}\" for i in range(79)]\n",
    "\n",
    "# Number of validation dates to use\n",
    "num_valid_dates = 100\n",
    "\n",
    "# Number of dates to skip from the beginning of the dataset\n",
    "skip_dates = 500\n",
    "\n",
    "# Number of folds for cross-validation\n",
    "N_fold = 5\n",
    "\n",
    "# If in training mode, load the training data\n",
    "if TRAINING:\n",
    "    # Load the training data from a Parquet file\n",
    "    df = pd.read_parquet(f'{input_path}/train.parquet')\n",
    "\n",
    "    # Reduce memory usage of the DataFrame (function not provided here)\n",
    "    df = reduce_mem_usage(df, False)\n",
    "\n",
    "    # Filter the DataFrame to include only dates greater than or equal to `skip_dates`\n",
    "    df = df[df['date_id'] >= skip_dates].reset_index(drop=True)\n",
    "\n",
    "    # Get unique dates from the DataFrame\n",
    "    dates = df['date_id'].unique()\n",
    "\n",
    "    # Define validation dates as the last `num_valid_dates` dates\n",
    "    valid_dates = dates[-num_valid_dates:]\n",
    "\n",
    "    # Define training dates as all dates except the last `num_valid_dates` dates\n",
    "    train_dates = dates[:-num_valid_dates]\n",
    "\n",
    "    # Display the last few rows of the DataFrame (for debugging purposes)\n",
    "    print(df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5f9ab5d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-28T14:13:30.514514Z",
     "iopub.status.busy": "2024-12-28T14:13:30.514197Z",
     "iopub.status.idle": "2024-12-28T14:13:51.166421Z",
     "shell.execute_reply": "2024-12-28T14:13:51.164822Z"
    },
    "papermill": {
     "duration": 20.657634,
     "end_time": "2024-12-28T14:13:51.168666",
     "exception": false,
     "start_time": "2024-12-28T14:13:30.511032",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [14:13:30] WARNING: /workspace/src/gbm/gbtree.cc:385: Changing updater from `grow_gpu_hist` to `grow_quantile_histmaker`.\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [14:13:30] WARNING: /workspace/src/context.cc:44: No visible GPU is found, setting device to CPU.\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [14:13:34] WARNING: /workspace/src/gbm/gbtree.cc:385: Changing updater from `grow_gpu_hist` to `grow_quantile_histmaker`.\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [14:13:34] WARNING: /workspace/src/context.cc:44: No visible GPU is found, setting device to CPU.\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [14:13:39] WARNING: /workspace/src/gbm/gbtree.cc:385: Changing updater from `grow_gpu_hist` to `grow_quantile_histmaker`.\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [14:13:39] WARNING: /workspace/src/context.cc:44: No visible GPU is found, setting device to CPU.\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [14:13:43] WARNING: /workspace/src/gbm/gbtree.cc:385: Changing updater from `grow_gpu_hist` to `grow_quantile_histmaker`.\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [14:13:43] WARNING: /workspace/src/context.cc:44: No visible GPU is found, setting device to CPU.\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [14:13:47] WARNING: /workspace/src/gbm/gbtree.cc:385: Changing updater from `grow_gpu_hist` to `grow_quantile_histmaker`.\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [14:13:47] WARNING: /workspace/src/context.cc:44: No visible GPU is found, setting device to CPU.\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# Create a directory to store the trained models\n",
    "os.system('mkdir models')\n",
    "\n",
    "# Define the path to load pre-trained models (if not in training mode)\n",
    "model_path = '/kaggle/input/js-data'\n",
    "\n",
    "# If in training mode, prepare validation data\n",
    "if TRAINING:\n",
    "    # Extract features, target, and weights for validation dates\n",
    "    X_valid = df[feature_names].loc[df['date_id'].isin(valid_dates)]\n",
    "    y_valid = df['responder_6'].loc[df['date_id'].isin(valid_dates)]\n",
    "    w_valid = df['weight'].loc[df['date_id'].isin(valid_dates)]\n",
    "\n",
    "# Initialize a list to store trained models\n",
    "models = []\n",
    "\n",
    "# Function to train a model or load a pre-trained model\n",
    "def train(model_dict, model_name='lgb'):\n",
    "    if TRAINING:\n",
    "        # Select dates for training based on the fold number\n",
    "        selected_dates = [date for ii, date in enumerate(train_dates) if ii % N_fold != i]\n",
    "\n",
    "        # Get the model from the dictionary\n",
    "        model = model_dict[model_name]\n",
    "\n",
    "        # Extract features, target, and weights for the selected training dates\n",
    "        X_train = df[feature_names].loc[df['date_id'].isin(selected_dates)]\n",
    "        y_train = df['responder_6'].loc[df['date_id'].isin(selected_dates)]\n",
    "        w_train = df['weight'].loc[df['date_id'].isin(selected_dates)]\n",
    "\n",
    "        # Train the model based on the type (LightGBM, XGBoost, or CatBoost)\n",
    "        if model_name == 'lgb':\n",
    "            # Train LightGBM model with early stopping and evaluation logging\n",
    "            model.fit(X_train, y_train, w_train,\n",
    "                      eval_metric=['r2_lgb'],\n",
    "                      eval_set=[(X_valid, y_valid, w_valid)],\n",
    "                      callbacks=[\n",
    "                          lgb.early_stopping(100),\n",
    "                          lgb.log_evaluation(10)\n",
    "                      ])\n",
    "        elif model_name == 'cbt':\n",
    "            # Prepare evaluation set for CatBoost\n",
    "            evalset = cbt.Pool(X_valid, y_valid, weight=w_valid)\n",
    "\n",
    "            # Train CatBoost model with early stopping and verbose logging\n",
    "            model.fit(X_train, y_train, sample_weight=w_train,\n",
    "                      eval_set=evalset,\n",
    "                      verbose=10,\n",
    "                      early_stopping_rounds=100)\n",
    "        else:\n",
    "            # Train XGBoost model with early stopping and verbose logging\n",
    "            model.fit(X_train, y_train, sample_weight=w_train,\n",
    "                      eval_set=[(X_valid, y_valid)],\n",
    "                      sample_weight_eval_set=[w_valid],\n",
    "                      verbose=10,\n",
    "                      early_stopping_rounds=100)\n",
    "\n",
    "        # Append the trained model to the list\n",
    "        models.append(model)\n",
    "\n",
    "        # Save the trained model to a file\n",
    "        joblib.dump(model, f'./models/{model_name}_{i}.model')\n",
    "\n",
    "        # Delete training data to free up memory\n",
    "        del X_train\n",
    "        del y_train\n",
    "        del w_train\n",
    "\n",
    "        # Collect garbage to free up memory\n",
    "        import gc\n",
    "        gc.collect()\n",
    "\n",
    "    else:\n",
    "        # If not in training mode, load the pre-trained model from the specified path\n",
    "        models.append(joblib.load(f'{model_path}/{model_name}_{i}.model'))\n",
    "\n",
    "    return\n",
    "\n",
    "# Custom R2 metric for XGBoost\n",
    "def r2_xgb(y_true, y_pred, sample_weight):\n",
    "    r2 = 1 - np.average((y_pred - y_true) ** 2, weights=sample_weight) / (np.average((y_true) ** 2, weights=sample_weight))\n",
    "    return -r2\n",
    "\n",
    "# Custom R2 metric for LightGBM\n",
    "def r2_lgb(y_true, y_pred, sample_weight):\n",
    "    r2 = 1 - np.average((y_pred - y_true) ** 2, weights=sample_weight) / (np.average((y_true) ** 2, weights=sample_weight))\n",
    "    return 'r2', r2, True\n",
    "\n",
    "# Custom R2 metric for CatBoost\n",
    "class r2_cbt(object):\n",
    "    def final_error(self, error, weight):\n",
    "        return 1 - error / (weight + 1e-38)\n",
    "\n",
    "    def is_max_optimal(self):\n",
    "        return True\n",
    "\n",
    "    def evaluate(self, approxes, target, weight):\n",
    "        assert len(approxes) == 1\n",
    "        assert len(target) == len(approxes[0])\n",
    "\n",
    "        approx = approxes[0]\n",
    "        error_sum = 0.0\n",
    "        weight_sum = 0.0\n",
    "\n",
    "        for i in range(len(approx)):\n",
    "            w = 1.0 if weight is None else weight[i]\n",
    "            weight_sum += w * (target[i] ** 2)\n",
    "            error_sum += w * ((approx[i] - target[i]) ** 2)\n",
    "\n",
    "        return error_sum, weight_sum\n",
    "\n",
    "# Dictionary to store different models with their configurations\n",
    "model_dict = {\n",
    "    'lgb': lgb.LGBMRegressor(n_estimators=500, device='gpu', gpu_use_dp=True, objective='l2'),\n",
    "    'xgb': xgb.XGBRegressor(n_estimators=2000, learning_rate=0.1, max_depth=6, tree_method='hist', device='gpu'),\n",
    "    'cbt': cbt.CatBoostRegressor(iterations=1000, learning_rate=0.05, task_type='GPU', loss_function='RMSE')\n",
    "}\n",
    "\n",
    "# Train models for each fold\n",
    "for i in range(N_fold):\n",
    "    train(model_dict, 'lgb')\n",
    "    train(model_dict, 'xgb')\n",
    "    train(model_dict, 'cbt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c778f651",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-28T14:13:51.176734Z",
     "iopub.status.busy": "2024-12-28T14:13:51.176329Z",
     "iopub.status.idle": "2024-12-28T14:13:51.183757Z",
     "shell.execute_reply": "2024-12-28T14:13:51.182735Z"
    },
    "papermill": {
     "duration": 0.013146,
     "end_time": "2024-12-28T14:13:51.185569",
     "exception": false,
     "start_time": "2024-12-28T14:13:51.172423",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "lags_ : pl.DataFrame | None = None\n",
    "\n",
    "# Replace this function with your inference code.\n",
    "# You can return either a Pandas or Polars dataframe, though Polars is recommended.\n",
    "# Each batch of predictions (except the very first) must be returned within 10 minutes of the batch features being provided.\n",
    "def predict(test: pl.DataFrame, lags: pl.DataFrame | None) -> pl.DataFrame | pd.DataFrame:\n",
    "    \"\"\"Make a prediction.\"\"\"\n",
    "    # All the responders from the previous day are passed in at time_id == 0. We save them in a global variable for access at every time_id.\n",
    "    # Use them as extra features, if you like.\n",
    "    global lags_\n",
    "    if lags is not None:\n",
    "        lags_ = lags\n",
    "\n",
    "    predictions = test.select(\n",
    "        'row_id',\n",
    "        pl.lit(0.0).alias('responder_6'),\n",
    "    )\n",
    "    \n",
    "    feat = test[feature_names].to_numpy()\n",
    "    \n",
    "    pred = [model.predict(feat) for model in models]\n",
    "    pred = np.mean(pred, axis=0)\n",
    "    \n",
    "    predictions = predictions.with_columns(pl.Series('responder_6', pred.ravel()))\n",
    "\n",
    "    # The predict function must return a DataFrame\n",
    "    assert isinstance(predictions, pl.DataFrame | pd.DataFrame)\n",
    "    # with columns 'row_id', 'responer_6'\n",
    "    assert list(predictions.columns) == ['row_id', 'responder_6']\n",
    "    # and as many rows as the test data.\n",
    "    assert len(predictions) == len(test)\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e6634ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-28T14:13:51.192413Z",
     "iopub.status.busy": "2024-12-28T14:13:51.192058Z",
     "iopub.status.idle": "2024-12-28T14:13:51.668956Z",
     "shell.execute_reply": "2024-12-28T14:13:51.667708Z"
    },
    "papermill": {
     "duration": 0.482607,
     "end_time": "2024-12-28T14:13:51.671000",
     "exception": false,
     "start_time": "2024-12-28T14:13:51.188393",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "inference_server = kaggle_evaluation.jane_street_inference_server.JSInferenceServer(predict)\n",
    "\n",
    "if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "    inference_server.serve()\n",
    "else:\n",
    "    inference_server.run_local_gateway(\n",
    "        (\n",
    "            '/kaggle/input/jane-street-real-time-market-data-forecasting/test.parquet',\n",
    "            '/kaggle/input/jane-street-real-time-market-data-forecasting/lags.parquet',\n",
    "        )\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 9871156,
     "sourceId": 84493,
     "sourceType": "competition"
    },
    {
     "datasetId": 6389121,
     "sourceId": 10319625,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30822,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 29.749483,
   "end_time": "2024-12-28T14:13:52.697229",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-12-28T14:13:22.947746",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
